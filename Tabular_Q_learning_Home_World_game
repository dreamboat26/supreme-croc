Write a run_episode function that takes a boolean argument (whether the epsiode is a training episode or not) and runs one episode. 

def run_episode(for_training):
    """ Runs one episode
    If for training, update Q function
    If for testing, computes and return cumulative discounted reward

    Args:
        for_training (bool): True if for training

    Returns:
        None
    """
    epsilon = TRAINING_EP if for_training else TESTING_EP

    # initialize for each episode
    # TODO Your code here

    (current_room_desc, current_quest_desc, terminal) = framework.newGame()
    
    # initial value 
    count = 0
    epi_reward = 0

    while not terminal:
        # Choose next action and execute
        # TODO Your code here

        # recall index from dictionary by "description" key
        current_state_1 = dict_room_desc[current_room_desc]
        current_state_2 = dict_quest_desc[current_quest_desc]

        (action_index, object_index) = epsilon_greedy(current_state_1, current_state_2, q_func, epsilon)

        (next_room_desc, next_quest_desc, reward, terminal) \
            = framework.step_game(current_room_desc, current_quest_desc, action_index, object_index) 

        next_state_1 = dict_room_desc[next_room_desc]
        next_state_2 = dict_quest_desc[next_quest_desc]

        if for_training:
            # update Q-function.
            # TODO Your code here
            tabular_q_learning(q_func, current_state_1, current_state_2, action_index, object_index, 
            reward, next_state_1, next_state_2, terminal)


        if not for_training:
            # update reward
            # TODO Your code here
            epi_reward += np.power(GAMMA, count)*reward

        # prepare next step
        # TODO Your code here
        count += 1
        current_room_desc = next_room_desc
        current_quest_desc = next_quest_desc

    if not for_training:
        return epi_reward


